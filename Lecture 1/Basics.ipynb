{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics\n",
    "\n",
    "---\n",
    "\n",
    "This will be a brief introduction to **[DataFrames.jl](https://dataframes.juliadata.org/stable/)**, data analysis library in Julia. More to go in the second lecture. However, during this quick intro to `DataFrames.jl`, we will cover one of the most important aspect in data analysis - **how to read and write different data** along with checking data shape and size.\n",
    "\n",
    "> **Note: Write functionality is not yet implemented in `Queryverse` library!**\n",
    "\n",
    "\n",
    "\n",
    "### Lecture outline\n",
    "\n",
    "---\n",
    "\n",
    "* Read Data\n",
    "\n",
    "\n",
    "* Write Data\n",
    "\n",
    "\n",
    "* Data Size and Shape\n",
    "\n",
    "\n",
    "* Summary Statistics\n",
    "\n",
    "\n",
    "* Unique Observations\n",
    "\n",
    "\n",
    "* Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:38.612000+04:00",
     "start_time": "2021-05-06T09:28:20.101Z"
    }
   },
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using StatsBase\n",
    "using Queryverse\n",
    "using DataFrames\n",
    "using FreqTables\n",
    "using Pipe: @pipe # To chain the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:39.629000+04:00",
     "start_time": "2021-05-06T09:28:23.532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"1.5.3\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Julia version\n",
    "\n",
    "VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:44.758000+04:00",
     "start_time": "2021-05-06T09:28:44.605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set number of columns to be shown\n",
    "ENV[\"COLUMNS\"] = 1000\n",
    "\n",
    "# Ser number of rows to be shown\n",
    "ENV[\"LINES\"] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "---\n",
    "\n",
    "Reading data file is THE FIRST operation you will do during data analysis. You have to be able to read different format of data file. Let start with the simplest common one, the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:55.247000+04:00",
     "start_time": "2021-05-06T09:28:46.259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Serial No.</th><th>GRE Score</th><th>TOEFL Score</th><th>University Rating</th><th>SOP</th><th>LOR</th><th>CGPA</th><th>Research</th><th>Chance of Admit </th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 9 columns</p><tr><th>1</th><td>1</td><td>337</td><td>118</td><td>4</td><td>4.5</td><td>4.5</td><td>9.65</td><td>1</td><td>0.92</td></tr><tr><th>2</th><td>2</td><td>324</td><td>107</td><td>4</td><td>4.0</td><td>4.5</td><td>8.87</td><td>1</td><td>0.76</td></tr><tr><th>3</th><td>3</td><td>316</td><td>104</td><td>3</td><td>3.0</td><td>3.5</td><td>8.0</td><td>1</td><td>0.72</td></tr><tr><th>4</th><td>4</td><td>322</td><td>110</td><td>3</td><td>3.5</td><td>2.5</td><td>8.67</td><td>1</td><td>0.8</td></tr><tr><th>5</th><td>5</td><td>314</td><td>103</td><td>2</td><td>2.0</td><td>3.0</td><td>8.21</td><td>0</td><td>0.65</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Serial No. & GRE Score & TOEFL Score & University Rating & SOP & LOR & CGPA & Research & Chance of Admit \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & Float64 & Float64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 337 & 118 & 4 & 4.5 & 4.5 & 9.65 & 1 & 0.92 \\\\\n",
       "\t2 & 2 & 324 & 107 & 4 & 4.0 & 4.5 & 8.87 & 1 & 0.76 \\\\\n",
       "\t3 & 3 & 316 & 104 & 3 & 3.0 & 3.5 & 8.0 & 1 & 0.72 \\\\\n",
       "\t4 & 4 & 322 & 110 & 3 & 3.5 & 2.5 & 8.67 & 1 & 0.8 \\\\\n",
       "\t5 & 5 & 314 & 103 & 2 & 2.0 & 3.0 & 8.21 & 0 & 0.65 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×9 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Serial No. \u001b[0m\u001b[1m GRE Score \u001b[0m\u001b[1m TOEFL Score \u001b[0m\u001b[1m University Rating \u001b[0m\u001b[1m SOP     \u001b[0m\u001b[1m LOR     \u001b[0m\u001b[1m CGPA    \u001b[0m\u001b[1m Research \u001b[0m\u001b[1m Chance of Admit  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64      \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64             \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Float64          \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "   1 │          1        337          118                  4      4.5      4.5     9.65         1              0.92\n",
       "   2 │          2        324          107                  4      4.0      4.5     8.87         1              0.76\n",
       "   3 │          3        316          104                  3      3.0      3.5     8.0          1              0.72\n",
       "   4 │          4        322          110                  3      3.5      2.5     8.67         1              0.8\n",
       "   5 │          5        314          103                  2      2.0      3.0     8.21         0              0.65"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = DataFrame(load(\"data/admission.csv\"))\n",
    "\n",
    "first(csv_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:57.286000+04:00",
     "start_time": "2021-05-06T09:28:46.734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>String</th><th>String</th><th>Float64?</th><th>Float64</th><th>Float64</th><th>Any</th><th>Float64</th><th>String?</th><th>String?</th></tr></thead><tbody><p>5 rows × 12 columns</p><tr><th>1</th><td>1.0</td><td>0.0</td><td>3.0</td><td>Braund, Mr. Owen Harris</td><td>male</td><td>22.0</td><td>1.0</td><td>0.0</td><td>A/5 21171</td><td>7.25</td><td><em>missing</em></td><td>S</td></tr><tr><th>2</th><td>2.0</td><td>1.0</td><td>1.0</td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female</td><td>38.0</td><td>1.0</td><td>0.0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><th>3</th><td>3.0</td><td>1.0</td><td>3.0</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26.0</td><td>0.0</td><td>0.0</td><td>STON/O2. 3101282</td><td>7.925</td><td><em>missing</em></td><td>S</td></tr><tr><th>4</th><td>4.0</td><td>1.0</td><td>1.0</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35.0</td><td>1.0</td><td>0.0</td><td>113803.0</td><td>53.1</td><td>C123</td><td>S</td></tr><tr><th>5</th><td>5.0</td><td>0.0</td><td>3.0</td><td>Allen, Mr. William Henry</td><td>male</td><td>35.0</td><td>0.0</td><td>0.0</td><td>373450.0</td><td>8.05</td><td><em>missing</em></td><td>S</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccccc}\n",
       "\t& PassengerId & Survived & Pclass & Name & Sex & Age & SibSp & Parch & Ticket & Fare & Cabin & Embarked\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & String & String & Float64? & Float64 & Float64 & Any & Float64 & String? & String?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1.0 & 0.0 & 3.0 & Braund, Mr. Owen Harris & male & 22.0 & 1.0 & 0.0 & A/5 21171 & 7.25 & \\emph{missing} & S \\\\\n",
       "\t2 & 2.0 & 1.0 & 1.0 & Cumings, Mrs. John Bradley (Florence Briggs Thayer) & female & 38.0 & 1.0 & 0.0 & PC 17599 & 71.2833 & C85 & C \\\\\n",
       "\t3 & 3.0 & 1.0 & 3.0 & Heikkinen, Miss. Laina & female & 26.0 & 0.0 & 0.0 & STON/O2. 3101282 & 7.925 & \\emph{missing} & S \\\\\n",
       "\t4 & 4.0 & 1.0 & 1.0 & Futrelle, Mrs. Jacques Heath (Lily May Peel) & female & 35.0 & 1.0 & 0.0 & 113803.0 & 53.1 & C123 & S \\\\\n",
       "\t5 & 5.0 & 0.0 & 3.0 & Allen, Mr. William Henry & male & 35.0 & 0.0 & 0.0 & 373450.0 & 8.05 & \\emph{missing} & S \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×12 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m PassengerId \u001b[0m\u001b[1m Survived \u001b[0m\u001b[1m Pclass  \u001b[0m\u001b[1m Name                              \u001b[0m\u001b[1m Sex    \u001b[0m\u001b[1m Age      \u001b[0m\u001b[1m SibSp   \u001b[0m\u001b[1m Parch   \u001b[0m\u001b[1m Ticket           \u001b[0m\u001b[1m Fare    \u001b[0m\u001b[1m Cabin   \u001b[0m\u001b[1m Embarked \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64  \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String                            \u001b[0m\u001b[90m String \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Any              \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String? \u001b[0m\u001b[90m String?  \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "   1 │         1.0       0.0      3.0  Braund, Mr. Owen Harris            male        22.0      1.0      0.0  A/5 21171          7.25   \u001b[90m missing \u001b[0m S\n",
       "   2 │         2.0       1.0      1.0  Cumings, Mrs. John Bradley (Flor…  female      38.0      1.0      0.0  PC 17599          71.2833  C85      C\n",
       "   3 │         3.0       1.0      3.0  Heikkinen, Miss. Laina             female      26.0      0.0      0.0  STON/O2. 3101282   7.925  \u001b[90m missing \u001b[0m S\n",
       "   4 │         4.0       1.0      1.0  Futrelle, Mrs. Jacques Heath (Li…  female      35.0      1.0      0.0  113803.0          53.1     C123     S\n",
       "   5 │         5.0       0.0      3.0  Allen, Mr. William Henry           male        35.0      0.0      0.0  373450.0           8.05   \u001b[90m missing \u001b[0m S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file = DataFrame(load(\"data/titanic.xlsx\", \"train\"))\n",
    "\n",
    "first(excel_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:58.520000+04:00",
     "start_time": "2021-05-06T09:28:47.299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>year</th><th>y</th><th>w</th><th>r</th><th>l</th><th>k</th></tr><tr><th></th><th>Int16?</th><th>Float32?</th><th>Float32?</th><th>Float32?</th><th>Float32?</th><th>Float32?</th></tr></thead><tbody><p>5 rows × 6 columns</p><tr><th>1</th><td>1948</td><td>1.214</td><td>0.243</td><td>0.1454</td><td>1.415</td><td>0.612</td></tr><tr><th>2</th><td>1949</td><td>1.354</td><td>0.26</td><td>0.2181</td><td>1.384</td><td>0.559</td></tr><tr><th>3</th><td>1950</td><td>1.569</td><td>0.278</td><td>0.3157</td><td>1.388</td><td>0.573</td></tr><tr><th>4</th><td>1951</td><td>1.948</td><td>0.297</td><td>0.394</td><td>1.55</td><td>0.564</td></tr><tr><th>5</th><td>1952</td><td>2.265</td><td>0.31</td><td>0.3559</td><td>1.802</td><td>0.574</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& year & y & w & r & l & k\\\\\n",
       "\t\\hline\n",
       "\t& Int16? & Float32? & Float32? & Float32? & Float32? & Float32?\\\\\n",
       "\t\\hline\n",
       "\t1 & 1948 & 1.214 & 0.243 & 0.1454 & 1.415 & 0.612 \\\\\n",
       "\t2 & 1949 & 1.354 & 0.26 & 0.2181 & 1.384 & 0.559 \\\\\n",
       "\t3 & 1950 & 1.569 & 0.278 & 0.3157 & 1.388 & 0.573 \\\\\n",
       "\t4 & 1951 & 1.948 & 0.297 & 0.394 & 1.55 & 0.564 \\\\\n",
       "\t5 & 1952 & 2.265 & 0.31 & 0.3559 & 1.802 & 0.574 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m year   \u001b[0m\u001b[1m y        \u001b[0m\u001b[1m w        \u001b[0m\u001b[1m r        \u001b[0m\u001b[1m l        \u001b[0m\u001b[1m k        \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int16? \u001b[0m\u001b[90m Float32? \u001b[0m\u001b[90m Float32? \u001b[0m\u001b[90m Float32? \u001b[0m\u001b[90m Float32? \u001b[0m\u001b[90m Float32? \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────\n",
       "   1 │   1948     1.214     0.243    0.1454     1.415     0.612\n",
       "   2 │   1949     1.354     0.26     0.2181     1.384     0.559\n",
       "   3 │   1950     1.569     0.278    0.3157     1.388     0.573\n",
       "   4 │   1951     1.948     0.297    0.394      1.55      0.564\n",
       "   5 │   1952     2.265     0.31     0.3559     1.802     0.574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stata_file = DataFrame(load(\"data/airline.dta\"))\n",
    "\n",
    "first(stata_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:28:58.826000+04:00",
     "start_time": "2021-05-06T09:28:47.696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>ADULTS</th><th>KIDS</th><th>INCOME</th><th>CONSUME</th></tr><tr><th></th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th></tr></thead><tbody><p>5 rows × 4 columns</p><tr><th>1</th><td>2.0</td><td>2.0</td><td>758.0</td><td>1.0</td></tr><tr><th>2</th><td>2.0</td><td>3.0</td><td>1785.0</td><td>1.0</td></tr><tr><th>3</th><td>3.0</td><td>0.0</td><td>1200.0</td><td>1.0</td></tr><tr><th>4</th><td>1.0</td><td>0.0</td><td>545.0</td><td>1.0</td></tr><tr><th>5</th><td>4.0</td><td>1.0</td><td>547.0</td><td>1.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& ADULTS & KIDS & INCOME & CONSUME\\\\\n",
       "\t\\hline\n",
       "\t& Float64? & Float64? & Float64? & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & 2.0 & 2.0 & 758.0 & 1.0 \\\\\n",
       "\t2 & 2.0 & 3.0 & 1785.0 & 1.0 \\\\\n",
       "\t3 & 3.0 & 0.0 & 1200.0 & 1.0 \\\\\n",
       "\t4 & 1.0 & 0.0 & 545.0 & 1.0 \\\\\n",
       "\t5 & 4.0 & 1.0 & 547.0 & 1.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m ADULTS   \u001b[0m\u001b[1m KIDS     \u001b[0m\u001b[1m INCOME   \u001b[0m\u001b[1m CONSUME  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\n",
       "─────┼────────────────────────────────────────\n",
       "   1 │      2.0       2.0     758.0       1.0\n",
       "   2 │      2.0       3.0    1785.0       1.0\n",
       "   3 │      3.0       0.0    1200.0       1.0\n",
       "   4 │      1.0       0.0     545.0       1.0\n",
       "   5 │      4.0       1.0     547.0       1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sas_file = DataFrame(load(\"data/alcohol.sas7bdat\"))\n",
    "\n",
    "first(sas_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:00.082000+04:00",
     "start_time": "2021-05-06T09:28:48.099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>id</th><th>sex</th><th>age</th><th>marital</th><th>edlevel</th><th>weight</th><th>height</th><th>healthrate</th><th>fitrate</th><th>weightrate</th><th>smoke</th><th>smokenum</th><th>alchohol</th><th>caffeine</th><th>hourwnit</th><th>hourwend</th><th>hourneed</th><th>trubslep</th><th>trubstay</th><th>wakenite</th><th>niteshft</th><th>liteslp</th><th>refreshd</th><th>satsleep</th><th>qualslp</th><th>stressmo</th><th>medhelp</th><th>problem</th><th>impact1</th><th>impact2</th><th>impact3</th><th>impact4</th><th>impact5</th><th>impact6</th><th>impact7</th><th>stopb</th><th>restlss</th><th>drvsleep</th><th>drvresul</th><th>ess</th><th>anxiety</th><th>depress</th><th>fatigue</th><th>lethargy</th><th>tired</th><th>sleepy</th><th>energy</th><th>stayslprec</th><th>getsleprec</th><th>qualsleeprec</th><th>totsas</th><th>cigsgp3</th><th>agegp3</th><th>probsleeprec</th><th>drvslprec</th></tr><tr><th></th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th><th>Float64?</th></tr></thead><tbody><p>5 rows × 55 columns</p><tr><th>1</th><td>83.0</td><td>0.0</td><td>42.0</td><td>2.0</td><td>2.0</td><td>52.0</td><td>162.0</td><td>10.0</td><td>7.0</td><td>5.0</td><td>1.0</td><td>15.0</td><td>3.0</td><td>5.0</td><td>9.0</td><td>9.0</td><td>9.0</td><td><em>missing</em></td><td><em>missing</em></td><td>1.0</td><td>2.0</td><td>2.0</td><td>1.0</td><td>2.0</td><td>6.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>8.0</td><td>2.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td>4.0</td><td>10.0</td><td>2.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>2</th><td>294.0</td><td>0.0</td><td>54.0</td><td>2.0</td><td>5.0</td><td>65.0</td><td>174.0</td><td>8.0</td><td>7.0</td><td>5.0</td><td>2.0</td><td><em>missing</em></td><td>0.0</td><td>10.0</td><td>6.5</td><td>6.5</td><td>7.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>5.0</td><td>4.0</td><td>5.0</td><td>2.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td>2.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>17.0</td><td>6.0</td><td>2.0</td><td>2.0</td><td>3.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>1.0</td><td>1.0</td><td>3.0</td><td>20.0</td><td><em>missing</em></td><td>3.0</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>425.0</td><td>1.0</td><td><em>missing</em></td><td>2.0</td><td>2.0</td><td>89.0</td><td>170.0</td><td>6.0</td><td>5.0</td><td>7.0</td><td>2.0</td><td><em>missing</em></td><td>12.0</td><td>4.0</td><td>6.0</td><td>6.0</td><td>8.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>1.0</td><td>2.0</td><td>3.0</td><td>2.0</td><td>6.0</td><td>1.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td>2.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>13.0</td><td>9.0</td><td>10.0</td><td>7.0</td><td>7.0</td><td>6.0</td><td>6.0</td><td>5.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>31.0</td><td><em>missing</em></td><td><em>missing</em></td><td>0.0</td><td>1.0</td></tr><tr><th>4</th><td>64.0</td><td>0.0</td><td>41.0</td><td>2.0</td><td>5.0</td><td>66.0</td><td>178.0</td><td>9.0</td><td>7.0</td><td>5.0</td><td>1.0</td><td>5.0</td><td>2.0</td><td>3.0</td><td>7.0</td><td>8.0</td><td>8.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>4.0</td><td>4.0</td><td>8.0</td><td>2.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>12.0</td><td>8.0</td><td>3.0</td><td>7.0</td><td>7.0</td><td>6.0</td><td>6.0</td><td>8.0</td><td>0.0</td><td>1.0</td><td>3.0</td><td>34.0</td><td>1.0</td><td>2.0</td><td>0.0</td><td>0.0</td></tr><tr><th>5</th><td>536.0</td><td>0.0</td><td>39.0</td><td>2.0</td><td>5.0</td><td>62.0</td><td>160.0</td><td>9.0</td><td>5.0</td><td>7.0</td><td>2.0</td><td><em>missing</em></td><td>1.0</td><td>6.0</td><td>7.0</td><td>7.0</td><td>7.5</td><td>1.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>1.0</td><td>2.0</td><td>4.0</td><td>6.0</td><td>2.0</td><td>2.0</td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td><em>missing</em></td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>12.0</td><td>4.0</td><td>0.0</td><td>5.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>6.0</td><td>1.0</td><td>1.0</td><td>3.0</td><td>25.0</td><td><em>missing</em></td><td>2.0</td><td>0.0</td><td>0.0</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccccccccccccccccccccccccccccccccccccccccccccccc}\n",
       "\t& id & sex & age & marital & edlevel & weight & height & healthrate & fitrate & weightrate & smoke & smokenum & alchohol & caffeine & hourwnit & hourwend & hourneed & trubslep & trubstay & wakenite & niteshft & liteslp & refreshd & satsleep & qualslp & stressmo & medhelp & problem & impact1 & impact2 & impact3 & impact4 & impact5 & impact6 & impact7 & stopb & restlss & drvsleep & drvresul & ess & anxiety & depress & fatigue & lethargy & tired & sleepy & energy & stayslprec & getsleprec & qualsleeprec & totsas & cigsgp3 & agegp3 & probsleeprec & drvslprec\\\\\n",
       "\t\\hline\n",
       "\t& Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64? & Float64?\\\\\n",
       "\t\\hline\n",
       "\t1 & 83.0 & 0.0 & 42.0 & 2.0 & 2.0 & 52.0 & 162.0 & 10.0 & 7.0 & 5.0 & 1.0 & 15.0 & 3.0 & 5.0 & 9.0 & 9.0 & 9.0 & \\emph{missing} & \\emph{missing} & 1.0 & 2.0 & 2.0 & 1.0 & 2.0 & 6.0 & 2.0 & 2.0 & 2.0 & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & 2.0 & 2.0 & 2.0 & 2.0 & 8.0 & 2.0 & 1.0 & 2.0 & 2.0 & 2.0 & 2.0 & 2.0 & \\emph{missing} & \\emph{missing} & 4.0 & 10.0 & 2.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t2 & 294.0 & 0.0 & 54.0 & 2.0 & 5.0 & 65.0 & 174.0 & 8.0 & 7.0 & 5.0 & 2.0 & \\emph{missing} & 0.0 & 10.0 & 6.5 & 6.5 & 7.0 & 1.0 & 1.0 & 1.0 & 2.0 & 1.0 & 1.0 & 5.0 & 4.0 & 5.0 & 2.0 & 2.0 & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & 2.0 & 1.0 & 2.0 & 2.0 & 17.0 & 6.0 & 2.0 & 2.0 & 3.0 & 5.0 & 5.0 & 5.0 & 1.0 & 1.0 & 3.0 & 20.0 & \\emph{missing} & 3.0 & 0.0 & 0.0 \\\\\n",
       "\t3 & 425.0 & 1.0 & \\emph{missing} & 2.0 & 2.0 & 89.0 & 170.0 & 6.0 & 5.0 & 7.0 & 2.0 & \\emph{missing} & 12.0 & 4.0 & 6.0 & 6.0 & 8.0 & 1.0 & 1.0 & 1.0 & 2.0 & 1.0 & 2.0 & 3.0 & 2.0 & 6.0 & 1.0 & 2.0 & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & 2.0 & 1.0 & 1.0 & 1.0 & 13.0 & 9.0 & 10.0 & 7.0 & 7.0 & 6.0 & 6.0 & 5.0 & 1.0 & 1.0 & 1.0 & 31.0 & \\emph{missing} & \\emph{missing} & 0.0 & 1.0 \\\\\n",
       "\t4 & 64.0 & 0.0 & 41.0 & 2.0 & 5.0 & 66.0 & 178.0 & 9.0 & 7.0 & 5.0 & 1.0 & 5.0 & 2.0 & 3.0 & 7.0 & 8.0 & 8.0 & 1.0 & 2.0 & 2.0 & 2.0 & 2.0 & 2.0 & 4.0 & 4.0 & 8.0 & 2.0 & 2.0 & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & 2.0 & 2.0 & 2.0 & 2.0 & 12.0 & 8.0 & 3.0 & 7.0 & 7.0 & 6.0 & 6.0 & 8.0 & 0.0 & 1.0 & 3.0 & 34.0 & 1.0 & 2.0 & 0.0 & 0.0 \\\\\n",
       "\t5 & 536.0 & 0.0 & 39.0 & 2.0 & 5.0 & 62.0 & 160.0 & 9.0 & 5.0 & 7.0 & 2.0 & \\emph{missing} & 1.0 & 6.0 & 7.0 & 7.0 & 7.5 & 1.0 & 1.0 & 1.0 & 2.0 & 2.0 & 1.0 & 2.0 & 4.0 & 6.0 & 2.0 & 2.0 & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & \\emph{missing} & 2.0 & 2.0 & 2.0 & 2.0 & 12.0 & 4.0 & 0.0 & 5.0 & 3.0 & 5.0 & 6.0 & 6.0 & 1.0 & 1.0 & 3.0 & 25.0 & \\emph{missing} & 2.0 & 0.0 & 0.0 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×55 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m id       \u001b[0m\u001b[1m sex      \u001b[0m\u001b[1m age       \u001b[0m\u001b[1m marital  \u001b[0m\u001b[1m edlevel  \u001b[0m\u001b[1m weight   \u001b[0m\u001b[1m height   \u001b[0m\u001b[1m healthrate \u001b[0m\u001b[1m fitrate  \u001b[0m\u001b[1m weightrate \u001b[0m\u001b[1m smoke    \u001b[0m\u001b[1m smokenum  \u001b[0m\u001b[1m alchohol \u001b[0m\u001b[1m caffeine \u001b[0m\u001b[1m hourwnit \u001b[0m\u001b[1m hourwend \u001b[0m\u001b[1m hourneed \u001b[0m\u001b[1m trubslep  \u001b[0m\u001b[1m trubstay  \u001b[0m\u001b[1m wakenite \u001b[0m\u001b[1m niteshft \u001b[0m\u001b[1m liteslp  \u001b[0m\u001b[1m refreshd \u001b[0m\u001b[1m satsleep \u001b[0m\u001b[1m qualslp  \u001b[0m\u001b[1m stressmo \u001b[0m\u001b[1m medhelp  \u001b[0m\u001b[1m problem  \u001b[0m\u001b[1m impact1  \u001b[0m\u001b[1m impact2  \u001b[0m\u001b[1m impact3  \u001b[0m\u001b[1m impact4  \u001b[0m\u001b[1m impact5  \u001b[0m\u001b[1m impact6  \u001b[0m\u001b[1m impact7  \u001b[0m\u001b[1m stopb    \u001b[0m\u001b[1m restlss  \u001b[0m\u001b[1m drvsleep \u001b[0m\u001b[1m drvresul \u001b[0m\u001b[1m ess      \u001b[0m\u001b[1m anxiety  \u001b[0m\u001b[1m depress  \u001b[0m\u001b[1m fatigue  \u001b[0m\u001b[1m lethargy \u001b[0m\u001b[1m tired    \u001b[0m\u001b[1m sleepy   \u001b[0m\u001b[1m energy   \u001b[0m\u001b[1m stayslprec \u001b[0m\u001b[1m getsleprec \u001b[0m\u001b[1m qualsleeprec \u001b[0m\u001b[1m totsas   \u001b[0m\u001b[1m cigsgp3   \u001b[0m\u001b[1m agegp3    \u001b[0m\u001b[1m probsleeprec \u001b[0m\u001b[1m drvslprec \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64?   \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m Float64? \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?  \u001b[0m\u001b[90m Float64?     \u001b[0m\u001b[90m Float64?  \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "   1 │     83.0       0.0       42.0       2.0       2.0      52.0     162.0        10.0       7.0         5.0       1.0       15.0       3.0       5.0       9.0       9.0       9.0 \u001b[90m missing   \u001b[0m\u001b[90m missing   \u001b[0m      1.0       2.0       2.0       1.0       2.0       6.0       2.0       2.0       2.0 \u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m      2.0       2.0       2.0       2.0       8.0       2.0       1.0       2.0       2.0       2.0       2.0       2.0 \u001b[90m  missing   \u001b[0m\u001b[90m  missing   \u001b[0m          4.0      10.0        2.0        2.0           0.0        0.0\n",
       "   2 │    294.0       0.0       54.0       2.0       5.0      65.0     174.0         8.0       7.0         5.0       2.0 \u001b[90m missing   \u001b[0m      0.0      10.0       6.5       6.5       7.0        1.0        1.0       1.0       2.0       1.0       1.0       5.0       4.0       5.0       2.0       2.0 \u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m      2.0       1.0       2.0       2.0      17.0       6.0       2.0       2.0       3.0       5.0       5.0       5.0         1.0         1.0           3.0      20.0 \u001b[90m missing   \u001b[0m       3.0           0.0        0.0\n",
       "   3 │    425.0       1.0 \u001b[90m missing   \u001b[0m      2.0       2.0      89.0     170.0         6.0       5.0         7.0       2.0 \u001b[90m missing   \u001b[0m     12.0       4.0       6.0       6.0       8.0        1.0        1.0       1.0       2.0       1.0       2.0       3.0       2.0       6.0       1.0       2.0 \u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m      2.0       1.0       1.0       1.0      13.0       9.0      10.0       7.0       7.0       6.0       6.0       5.0         1.0         1.0           1.0      31.0 \u001b[90m missing   \u001b[0m\u001b[90m missing   \u001b[0m          0.0        1.0\n",
       "   4 │     64.0       0.0       41.0       2.0       5.0      66.0     178.0         9.0       7.0         5.0       1.0        5.0       2.0       3.0       7.0       8.0       8.0        1.0        2.0       2.0       2.0       2.0       2.0       4.0       4.0       8.0       2.0       2.0 \u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m      2.0       2.0       2.0       2.0      12.0       8.0       3.0       7.0       7.0       6.0       6.0       8.0         0.0         1.0           3.0      34.0        1.0        2.0           0.0        0.0\n",
       "   5 │    536.0       0.0       39.0       2.0       5.0      62.0     160.0         9.0       5.0         7.0       2.0 \u001b[90m missing   \u001b[0m      1.0       6.0       7.0       7.0       7.5        1.0        1.0       1.0       2.0       2.0       1.0       2.0       4.0       6.0       2.0       2.0 \u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m\u001b[90m  missing \u001b[0m      2.0       2.0       2.0       2.0      12.0       4.0       0.0       5.0       3.0       5.0       6.0       6.0         1.0         1.0           3.0      25.0 \u001b[90m missing   \u001b[0m       2.0           0.0        0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spss_file = DataFrame(load(\"data/sleep.sav\"))\n",
    "\n",
    "first(spss_file, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data\n",
    "\n",
    "---\n",
    "\n",
    "Writing data into a file is almost same procedure as reading. While writing data in a file, we have to indicate the address of new data file as well as the name of the file. Let write CSV and Excel file.\n",
    "\n",
    "**Writing other formats are not available right now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T12:32:02.233000+04:00",
     "start_time": "2021-05-06T08:32:01.493Z"
    }
   },
   "outputs": [],
   "source": [
    "save(\"data/new_csv_file.csv\", csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T12:32:07.844000+04:00",
     "start_time": "2021-05-06T08:32:04.285Z"
    }
   },
   "outputs": [],
   "source": [
    "save(\"data/new_excel_file.xlsx\", excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Size and Shape\n",
    "\n",
    "---\n",
    "\n",
    "We will talk about data size and shape in the second lecture. However, here we quickly cover what is it and how to use that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:06.365000+04:00",
     "start_time": "2021-05-06T09:29:06.123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(csv_file) # Retruns number of rows and columns, respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "---\n",
    "\n",
    "This is a summary statistics of your data. This gives you the quick sight of your data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:09.383000+04:00",
     "start_time": "2021-05-06T09:29:07.810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Float64</th><th>Real</th><th>Float64</th><th>Real</th><th>Int64</th><th>DataType</th></tr></thead><tbody><p>9 rows × 7 columns</p><tr><th>1</th><td>Serial No.</td><td>200.5</td><td>1</td><td>200.5</td><td>400</td><td>0</td><td>Int64</td></tr><tr><th>2</th><td>GRE Score</td><td>316.808</td><td>290</td><td>317.0</td><td>340</td><td>0</td><td>Int64</td></tr><tr><th>3</th><td>TOEFL Score</td><td>107.41</td><td>92</td><td>107.0</td><td>120</td><td>0</td><td>Int64</td></tr><tr><th>4</th><td>University Rating</td><td>3.0875</td><td>1</td><td>3.0</td><td>5</td><td>0</td><td>Int64</td></tr><tr><th>5</th><td>SOP</td><td>3.4</td><td>1.0</td><td>3.5</td><td>5.0</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>LOR</td><td>3.4525</td><td>1.0</td><td>3.5</td><td>5.0</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>CGPA</td><td>8.59893</td><td>6.8</td><td>8.61</td><td>9.92</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>Research</td><td>0.5475</td><td>0</td><td>1.0</td><td>1</td><td>0</td><td>Int64</td></tr><tr><th>9</th><td>Chance of Admit </td><td>0.72435</td><td>0.34</td><td>0.73</td><td>0.97</td><td>0</td><td>Float64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Real & Float64 & Real & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Serial No. & 200.5 & 1 & 200.5 & 400 & 0 & Int64 \\\\\n",
       "\t2 & GRE Score & 316.808 & 290 & 317.0 & 340 & 0 & Int64 \\\\\n",
       "\t3 & TOEFL Score & 107.41 & 92 & 107.0 & 120 & 0 & Int64 \\\\\n",
       "\t4 & University Rating & 3.0875 & 1 & 3.0 & 5 & 0 & Int64 \\\\\n",
       "\t5 & SOP & 3.4 & 1.0 & 3.5 & 5.0 & 0 & Float64 \\\\\n",
       "\t6 & LOR & 3.4525 & 1.0 & 3.5 & 5.0 & 0 & Float64 \\\\\n",
       "\t7 & CGPA & 8.59893 & 6.8 & 8.61 & 9.92 & 0 & Float64 \\\\\n",
       "\t8 & Research & 0.5475 & 0 & 1.0 & 1 & 0 & Int64 \\\\\n",
       "\t9 & Chance of Admit  & 0.72435 & 0.34 & 0.73 & 0.97 & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable          \u001b[0m\u001b[1m mean      \u001b[0m\u001b[1m min    \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max    \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol            \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Real   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Real   \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼───────────────────────────────────────────────────────────────────────────\n",
       "   1 │ Serial No.         200.5        1      200.5   400            0  Int64\n",
       "   2 │ GRE Score          316.808    290      317.0   340            0  Int64\n",
       "   3 │ TOEFL Score        107.41      92      107.0   120            0  Int64\n",
       "   4 │ University Rating    3.0875     1        3.0     5            0  Int64\n",
       "   5 │ SOP                  3.4        1.0      3.5     5.0          0  Float64\n",
       "   6 │ LOR                  3.4525     1.0      3.5     5.0          0  Float64\n",
       "   7 │ CGPA                 8.59893    6.8      8.61    9.92         0  Float64\n",
       "   8 │ Research             0.5475     0        1.0     1            0  Int64\n",
       "   9 │ Chance of Admit      0.72435    0.34     0.73    0.97         0  Float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Observations\n",
    "\n",
    "---\n",
    "\n",
    "Summary statistics does not give how many unique observations we have alongside columns. We can check it by using `unique()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:12.731000+04:00",
     "start_time": "2021-05-06T09:29:12.727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Serial No.</th><th>GRE Score</th><th>TOEFL Score</th><th>University Rating</th><th>SOP</th><th>LOR</th><th>CGPA</th><th>Research</th><th>Chance of Admit </th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 9 columns</p><tr><th>1</th><td>1</td><td>337</td><td>118</td><td>4</td><td>4.5</td><td>4.5</td><td>9.65</td><td>1</td><td>0.92</td></tr><tr><th>2</th><td>2</td><td>324</td><td>107</td><td>4</td><td>4.0</td><td>4.5</td><td>8.87</td><td>1</td><td>0.76</td></tr><tr><th>3</th><td>3</td><td>316</td><td>104</td><td>3</td><td>3.0</td><td>3.5</td><td>8.0</td><td>1</td><td>0.72</td></tr><tr><th>4</th><td>4</td><td>322</td><td>110</td><td>3</td><td>3.5</td><td>2.5</td><td>8.67</td><td>1</td><td>0.8</td></tr><tr><th>5</th><td>5</td><td>314</td><td>103</td><td>2</td><td>2.0</td><td>3.0</td><td>8.21</td><td>0</td><td>0.65</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Serial No. & GRE Score & TOEFL Score & University Rating & SOP & LOR & CGPA & Research & Chance of Admit \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & Float64 & Float64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 337 & 118 & 4 & 4.5 & 4.5 & 9.65 & 1 & 0.92 \\\\\n",
       "\t2 & 2 & 324 & 107 & 4 & 4.0 & 4.5 & 8.87 & 1 & 0.76 \\\\\n",
       "\t3 & 3 & 316 & 104 & 3 & 3.0 & 3.5 & 8.0 & 1 & 0.72 \\\\\n",
       "\t4 & 4 & 322 & 110 & 3 & 3.5 & 2.5 & 8.67 & 1 & 0.8 \\\\\n",
       "\t5 & 5 & 314 & 103 & 2 & 2.0 & 3.0 & 8.21 & 0 & 0.65 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×9 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Serial No. \u001b[0m\u001b[1m GRE Score \u001b[0m\u001b[1m TOEFL Score \u001b[0m\u001b[1m University Rating \u001b[0m\u001b[1m SOP     \u001b[0m\u001b[1m LOR     \u001b[0m\u001b[1m CGPA    \u001b[0m\u001b[1m Research \u001b[0m\u001b[1m Chance of Admit  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64      \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64             \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Float64          \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "   1 │          1        337          118                  4      4.5      4.5     9.65         1              0.92\n",
       "   2 │          2        324          107                  4      4.0      4.5     8.87         1              0.76\n",
       "   3 │          3        316          104                  3      3.0      3.5     8.0          1              0.72\n",
       "   4 │          4        322          110                  3      3.5      2.5     8.67         1              0.8\n",
       "   5 │          5        314          103                  2      2.0      3.0     8.21         0              0.65"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(csv_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:13.936000+04:00",
     "start_time": "2021-05-06T09:29:13.223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Int64,1}:\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(csv_file[!, \"Research\"]) # Only two unique values in \"Research\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Counts\n",
    "\n",
    "---\n",
    "\n",
    "We can count duplicated values across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:18.247000+04:00",
     "start_time": "2021-05-06T09:29:18.237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Serial No.</th><th>GRE Score</th><th>TOEFL Score</th><th>University Rating</th><th>SOP</th><th>LOR</th><th>CGPA</th><th>Research</th><th>Chance of Admit </th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 9 columns</p><tr><th>1</th><td>1</td><td>337</td><td>118</td><td>4</td><td>4.5</td><td>4.5</td><td>9.65</td><td>1</td><td>0.92</td></tr><tr><th>2</th><td>2</td><td>324</td><td>107</td><td>4</td><td>4.0</td><td>4.5</td><td>8.87</td><td>1</td><td>0.76</td></tr><tr><th>3</th><td>3</td><td>316</td><td>104</td><td>3</td><td>3.0</td><td>3.5</td><td>8.0</td><td>1</td><td>0.72</td></tr><tr><th>4</th><td>4</td><td>322</td><td>110</td><td>3</td><td>3.5</td><td>2.5</td><td>8.67</td><td>1</td><td>0.8</td></tr><tr><th>5</th><td>5</td><td>314</td><td>103</td><td>2</td><td>2.0</td><td>3.0</td><td>8.21</td><td>0</td><td>0.65</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Serial No. & GRE Score & TOEFL Score & University Rating & SOP & LOR & CGPA & Research & Chance of Admit \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Float64 & Float64 & Float64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 337 & 118 & 4 & 4.5 & 4.5 & 9.65 & 1 & 0.92 \\\\\n",
       "\t2 & 2 & 324 & 107 & 4 & 4.0 & 4.5 & 8.87 & 1 & 0.76 \\\\\n",
       "\t3 & 3 & 316 & 104 & 3 & 3.0 & 3.5 & 8.0 & 1 & 0.72 \\\\\n",
       "\t4 & 4 & 322 & 110 & 3 & 3.5 & 2.5 & 8.67 & 1 & 0.8 \\\\\n",
       "\t5 & 5 & 314 & 103 & 2 & 2.0 & 3.0 & 8.21 & 0 & 0.65 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×9 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Serial No. \u001b[0m\u001b[1m GRE Score \u001b[0m\u001b[1m TOEFL Score \u001b[0m\u001b[1m University Rating \u001b[0m\u001b[1m SOP     \u001b[0m\u001b[1m LOR     \u001b[0m\u001b[1m CGPA    \u001b[0m\u001b[1m Research \u001b[0m\u001b[1m Chance of Admit  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64      \u001b[0m\u001b[90m Int64     \u001b[0m\u001b[90m Int64       \u001b[0m\u001b[90m Int64             \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Float64          \u001b[0m\n",
       "─────┼──────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "   1 │          1        337          118                  4      4.5      4.5     9.65         1              0.92\n",
       "   2 │          2        324          107                  4      4.0      4.5     8.87         1              0.76\n",
       "   3 │          3        316          104                  3      3.0      3.5     8.0          1              0.72\n",
       "   4 │          4        322          110                  3      3.5      2.5     8.67         1              0.8\n",
       "   5 │          5        314          103                  2      2.0      3.0     8.21         0              0.65"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(csv_file, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:19.717000+04:00",
     "start_time": "2021-05-06T09:29:18.844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Named Array{Int64,1}\n",
       "Dim1  │ \n",
       "──────┼────\n",
       "0     │ 181\n",
       "1     │ 219"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.Research |> freqtable # We have 219 ones and 181 zeros, totaling to 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`|>` is a pipe or chaining operator and gives us possibility to chain the functions. This is equivalent of `.` operator in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:21.376000+04:00",
     "start_time": "2021-05-06T09:29:20.612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 2 entries:\n",
       "  0 => 181\n",
       "  1 => 219"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(csv_file.Research) # Same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T13:29:21.774000+04:00",
     "start_time": "2021-05-06T09:29:21.111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Named Array{Float64,1}\n",
       "Dim1  │ \n",
       "──────┼───────\n",
       "0     │ 0.4525\n",
       "1     │ 0.5475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file.Research |> freqtable |> prop # Proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "\n",
    "In this lecture, we learn how to set up our working environment as well as how to install necessary libraries for data analysis. Moreover, we have covered one of the most important aspect of data analysis - data reading and writing. In the next lecture, we will uncover `DataFrames.jl` capabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
